{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Régression Linéaire\n",
    "\n",
    "Modèle linéaire pour prédire le prix d'une voiture en fonction de son kilométrage."
   ],
   "id": "5710a59b859a94c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Définitions :\n",
    "\n",
    "- **Normalisation** : Redimensionner les variables numériques pour qu'elles soient comparables sur une échelle commune.\n",
    "- **Machine Learning** : Donner à une machine la capacité d'apprendre sans la programmer de façon explicite.\n",
    "- **Apprentissage supervisé** : Technique d'apprentissage la plus courante en machine learning. On donne des exemples à la machine qu'elle doit étudier pour en créer des modèles.\n",
    "- **Dataset** : Ensemble d'exemples données à la machine pour apprendre (tableau de données).\n",
    "- **Problème de regression** : On cherche à prédire la valeur d'une variable continue, c'est-à-dire une variable qui peux prendre une infinité de valeurs.\n",
    "- **Problème de classification** : On cherche à prédire la valeur d'une variable discrète, c'est-à-dire une variable qui prends certaines valeurs."
   ],
   "id": "efad5bf3dddef957"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prérequis :\n",
    "\n",
    "Pour travailler de manière plus optimale (pour faciliter les calculs notamment), l'utilisation de matrice est fortement recommandée."
   ],
   "id": "1e36cec2358f5815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:39:39.356630Z",
     "start_time": "2024-10-23T14:39:39.341788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sys import exit\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "\n",
    "Numbers = Union[int, float]\n",
    "\n",
    "class Matrix:\n",
    "    __list: List[List[Numbers]]\n",
    "    __rows: int\n",
    "    __cols: int\n",
    "\n",
    "    def __init__(self, matrix: List[List[Numbers]]) -> None:\n",
    "        self.__list = matrix\n",
    "        self.__rows = 0\n",
    "        self.__cols = 0\n",
    "        if len(matrix) != 0:\n",
    "            self._validate()\n",
    "\n",
    "    def _validate(self) -> None:\n",
    "        self.__rows = len(self.__list)\n",
    "        self.__cols = len(self.__list[0])\n",
    "        if not all([len(row) == self.__cols for row in self.__list]):\n",
    "            exit(\"All rows in the matrix must have equal number of columns.\")\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        separator: str = \"-\" * 9\n",
    "        if self.__cols == 0:\n",
    "            return f\"{separator}\\n{separator}\\n{self.shape()}\\n\"\n",
    "        matrix_str: str = \"\\n\".join(str(row) for row in self.__list)\n",
    "        return f\"{separator}\\n{matrix_str}\\n{separator}\\n{self.shape()}\\n\"\n",
    "\n",
    "    def _zeroed_matrix(self, sizes: Union[Tuple[int, int], None] = None) -> \"Matrix\":\n",
    "        if isinstance(sizes, Tuple):\n",
    "            return Matrix([[0] * sizes[1] for _ in range(sizes[0])])\n",
    "        else:\n",
    "            return Matrix([[0] * self.__cols for _ in range(self.__rows)])\n",
    "\n",
    "    def __add__(self, other: \"Matrix\") -> \"Matrix\":\n",
    "        if self.shape() != other.shape():\n",
    "            exit(\"Both matrices must have the same dimensions.\")\n",
    "        matrix: Matrix = self._zeroed_matrix()\n",
    "        for row in range(self.__rows):\n",
    "            for column in range(self.__cols):\n",
    "                matrix.__list[row][column] = self.__list[row][column] + other.__list[row][column]\n",
    "        return matrix\n",
    "\n",
    "    def __sub__(self, other: \"Matrix\") -> \"Matrix\":\n",
    "        if self.shape() != other.shape():\n",
    "            exit(\"Both matrices must have the same dimensions.\")\n",
    "        matrix: Matrix = self._zeroed_matrix()\n",
    "        for row in range(self.__rows):\n",
    "            for column in range(self.__cols):\n",
    "                matrix.__list[row][column] = self.__list[row][column] - other.__list[row][column]\n",
    "        return matrix\n",
    "\n",
    "    def __mul__(self, other: Union[\"Matrix\", Numbers]) -> \"Matrix\":\n",
    "        if isinstance(other, (int, float)):\n",
    "            matrix: Matrix = self._zeroed_matrix()\n",
    "            for row in range(self.__rows):\n",
    "                for column in range(self.__cols):\n",
    "                    matrix.__list[row][column] = self.__list[row][column] * other\n",
    "            return matrix\n",
    "        else:\n",
    "            if self.__cols != other.__rows:\n",
    "                exit(\"\")\n",
    "            matrix: Matrix = self._zeroed_matrix((self.__rows, other.__cols))\n",
    "            for i in range(self.__rows):\n",
    "                for j in range(other.__cols):\n",
    "                    for k in range(self.__cols):\n",
    "                        matrix.__list[i][j] += self.__list[i][k] * other.__list[k][j]\n",
    "            return matrix\n",
    "\n",
    "    def __eq__(self, other: \"Matrix\") -> bool:\n",
    "        return self.__list == other.__list\n",
    "\n",
    "    def get(self) -> List[List[Numbers]]:\n",
    "        return self.__list\n",
    "\n",
    "    def min(self) -> float:\n",
    "        return min(min(row) for row in self.__list)\n",
    "\n",
    "    def max(self) -> float:\n",
    "        return max(max(row) for row in self.__list)\n",
    "\n",
    "    def shape(self) -> Tuple[int, int]:\n",
    "        return self.__rows, self.__cols\n",
    "\n",
    "    def sum(self) -> Numbers:\n",
    "        return sum(sum(row) for row in self.__list)\n",
    "\n",
    "    def mean(self) -> float:\n",
    "        return self.sum() / (self.__rows * self.__cols)\n",
    "\n",
    "    def transpose(self) -> \"Matrix\":\n",
    "        matrix: Matrix = self._zeroed_matrix((self.__cols, self.__rows))\n",
    "        for row in range(self.__rows):\n",
    "            for column in range(self.__cols):\n",
    "                matrix.__list[column][row] = self.__list[row][column]\n",
    "        return matrix\n",
    "\n",
    "    def square(self) -> \"Matrix\":\n",
    "        matrix: Matrix = self._zeroed_matrix()\n",
    "        for row in range(self.__rows):\n",
    "            for column in range(self.__cols):\n",
    "                matrix.__list[row][column] = pow(self.__list[row][column], 2)\n",
    "        return matrix"
   ],
   "id": "b54936a192ce2e51",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étape 1 : Dataset\n",
    "\n",
    "La première étape consiste à récupérer les données de notre dataset. On va extraire deux matrices qui correspondent à notre target et nos features.\n",
    "Dans notre situation, nous avons donc un vecteur target (prix) et une matrice features (kilométrages).\n",
    "\n",
    "Voici une représentation de nos matrices :\n",
    "\n",
    "$$\n",
    "x = \\begin{pmatrix} 240000 \\cr 139800 \\cr \\ldots \\cr 61789 \\cr \\end {pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y = \\begin{pmatrix} 3650 \\cr 3800 \\cr \\ldots \\cr 8290 \\cr \\end {pmatrix}\n",
    "$$\n",
    "\n",
    "Par convention, on note $m$ le nombre d'exemple que l'on a dans notre dataset et on note $n$ le nombre de features que l'on a dans notre dataset. Notre matrice target a une taille de $(m, 1)$ et notre matrice features a une taille de $(m, n)$. Avec notre dataset, nous avons donc $m = 24$ et $n = 1$.\n",
    "\n",
    "Pour ce faire, voici une classe permettant d'extraire les données (à l'initialisation de notre classe) de notre dataset (notre fichier CSV) en Python."
   ],
   "id": "a49d520583e3a7c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:39:39.388343Z",
     "start_time": "2024-10-23T14:39:39.374554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from csv import reader\n",
    "from sys import exit\n",
    "from typing import List, Tuple\n",
    "\n",
    "def reader_csv(path: str) -> Tuple[Matrix, Matrix]:\n",
    "    target: List[List[float]] = []\n",
    "    features: List[List[float]] = []\n",
    "\n",
    "    try:\n",
    "        with open(path, mode=\"r\", newline=\"\") as file:\n",
    "            r = reader(file)\n",
    "            next(r)\n",
    "            for row in r:\n",
    "                target.append([float(row[1])])\n",
    "                features.append([float(row[0])])\n",
    "        return Matrix(target), Matrix(features)\n",
    "    except FileNotFoundError:\n",
    "        exit(f\"The file {path} does not exist.\")\n",
    "    except Exception as e:\n",
    "        exit(f\"An error occurred while reading the CSV file: {e}\")"
   ],
   "id": "65e7983d42b3ad8d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Raw Data Visualisation](images/raw_data.png)\n",
    "![Dataset representation](images/dataset.png)"
   ],
   "id": "a37859fb85d1e73e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étape 2 : Modèle\n",
    "\n",
    "À partir du dataset (et de la représentation graphique présente plus haut), on peux visualiser un nuage de points. Pour ce projet, nous allons utiliser un modèle linéaire, cependant il existe d'autres type de modèle disponible.\n",
    "\n",
    "Il est important de noter que c'est nous qui décidons de quel modèle la machine doit utiliser et c'est la machine qui doit apprendre les paramètres. Le modèle est une généralisation de l'ensemble des points de notre dataset, un bon modèle est un modèle qui nous donne les plus petites erreurs.\n",
    "\n",
    "Pour notre modèle linéaire, nous avons donc la formule suivante :\n",
    "\n",
    "$$\n",
    "f(x)=ax+b\n",
    "$$\n",
    "\n",
    "La formule sous forme matricielle :\n",
    "\n",
    "$$\n",
    "F = X \\cdot \\theta\n",
    "$$\n",
    "\n",
    "Avec :\n",
    "\n",
    "$$\n",
    "F = \\begin {bmatrix} f(x^1)\\cr f(x^2)\\cr \\ldots\\cr  f(x^m)\\cr\\end {bmatrix}\n",
    "X = \\begin {bmatrix} x^1 & 1\\cr x^2 & 1\\cr \\ldots & \\ldots\\cr x^m & 1\\cr\\end {bmatrix}\n",
    "\\theta = \\begin {bmatrix} a\\cr b \\end {bmatrix}\n",
    "$$\n",
    "\n",
    "Ce modèle a deux paramètres $a$ et $b$ (cf. coefficients polynome). Comme c'est la machine qui doit apprendre les paramètres, nous utiliserons au lancement du programme des paramètres aléatoire.\n",
    "\n",
    "Voici une fonction permettant de calculer notre model :"
   ],
   "id": "6932a60c5d4286cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:39:39.404938Z",
     "start_time": "2024-10-23T14:39:39.401614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model(x: Union[Matrix, float], theta: Matrix) -> Union[Matrix, float]:\n",
    "    if isinstance(x, float):\n",
    "        theta_value = theta.get()\n",
    "        return (theta_value[0][0] * x) + theta_value[1][0]\n",
    "    else:\n",
    "        return x * theta"
   ],
   "id": "a763f516b761e2e5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étape 3 : Fonction Coût\n",
    "\n",
    "La fonction coût (cf. Fonction Quadratique Moyenne) permet de calculer le coût entre le modèle qu'elle est en train de développer et les vraies valeur de target. Trouver le minimum de la fonction coût revient à trouver le meilleur modèle pour notre programme.\n",
    "\n",
    "La fonction va mesurer la distance entre la prédiction (le point sur notre droite) et la valeur réelle (cf. norme euclidienne), c'est ce que l'on nomme erreur. On va rassembler toutes les erreurs dans une fonction nommé $J$.\n",
    "\n",
    "Pour notre fonction coût, la formule est la suivate :\n",
    "\n",
    "$$\n",
    "J(a, b) = \\frac{1}{2m} \\displaystyle\\sum_{i=1}^m (f(x^i) - y^i)^2\n",
    "$$\n",
    "\n",
    "La formule sous forme matricielle :\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m} \\displaystyle\\sum_{i=1}^m (X \\cdot \\theta - Y)^2\n",
    "$$\n",
    "\n",
    "Voici une fonction représentant la fonction coût :"
   ],
   "id": "b171011161669f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T14:39:39.495578Z",
     "start_time": "2024-10-23T14:39:39.493281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cost_function(x: Matrix, y: Matrix, theta: Matrix) -> float:\n",
    "    m: int = x.shape()[0]\n",
    "    return (1 / (2 * m)) * (model(x, theta) - y).square().sum()"
   ],
   "id": "23ac5d97664bb567",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Cost function](images/cost.png)\n",
    "![Error model](images/model_error.png)"
   ],
   "id": "f44c2945b087ff35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étape 4 : Algorithme de minimisation\n",
    "\n",
    "L'algorithme de minimisation est une stratégie qui cherche à trouver quels sont les paramètres de notre modèle qui minimise la fonction coût, c'est-à-dire qui minimise l'ensemble de nos erreurs. Pour notre projet, nous utiliserons la déscente de gradient. La déscente de gradient est un algorithme d'optimisation qui converge vers le minimum d'une fonction convexe.\n",
    "\n",
    "Dans notre situation, la fonction coût à la même allure qu'une fonction carré (car on fait la somme de carré), c'est-à-dire une allure parabolique. Sur cette fonction, on recherche le minimum de $J$ par rapport à $a$. Pour ce faire, on choisi au hasard un point sur la courbe $J$, on va mesurer sa dérivé et on va aller dans la direction de la pente qui déscends. L'hyper-paramètre $\\alpha$ correspond à notre vitesse de convergence (aka. learning_rate).\n",
    "\n",
    "Pour notre déscente de gradient, voici les formules :\n",
    "\n",
    "$$\n",
    "a = a - \\alpha \\frac{\\partial J(a, b)}{\\partial a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\alpha \\frac{\\partial J(a, b)}{\\partial b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta}\n",
    "$$\n",
    "\n",
    "Pour calculer les dérivés de $a$ et $b$ par rapport à $J$, on utilise les formules suivantes :\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(a, b)}{\\partial a} = \\frac{1}{m} \\displaystyle\\sum_{i=1}^m x^i(ax^i + b - y^i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(a, b)}{\\partial b} = \\frac{1}{m} \\displaystyle\\sum_{i=1}^m 1(ax^i + b - y^i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta} = \\frac{1}{m} X^T (X \\cdot \\theta - Y)\n",
    "$$\n",
    "\n",
    "Avec :\n",
    "\n",
    "$$\n",
    "X^T = \\begin {bmatrix} x^1 & x^2 & x^3 & \\ldots & x^m\\cr 1 & 1 & 1 & \\ldots & 1 \\end {bmatrix}\n",
    "$$\n",
    "\n",
    "Voici un exemple de code pour la déscente de gradient :"
   ],
   "id": "ebb71cb291cba750"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def gradient(x: Matrix, y: Matrix, theta: Matrix) -> Matrix:\n",
    "    m: int = x.shape()[0]\n",
    "    return x.transpose() * (model(x, theta) - y) * (1 / m)\n",
    "\n",
    "def gradient_descent(x: Matrix, y: Matrix, theta: Matrix, learning_rate: float, iterations: int) -> Matrix:\n",
    "    for i in range(iterations):\n",
    "        theta = theta - (gradient(x, y, theta) * learning_rate)\n",
    "    return theta"
   ],
   "id": "d452c6f54b0267a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Regressions](images/regression.png)\n",
    "![Square function](images/squared_function.png)"
   ],
   "id": "ea89907d4445bc54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Étape 5 : Coéfficient de détermination\n",
    "\n",
    "Pour calculer la précision de notre modèle (cf. coefficient de determination), on utilise la formule suivante :\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\displaystyle\\sum_{i=1}^n (y^i - \\overline{y}^i)^2}{\\displaystyle\\sum_{i=1}^n (y^i - \\overline{y})^2}\n",
    "$$\n",
    "\n",
    "Où $n$ est le nombre de mesure, $y^i$ est la valeur de la ième valeur, $\\overline{y}^i$ est la valeur prédite correspondante et $\\overline{y}$ est la moyenne des mesures.\n",
    "\n",
    "Voici une implémentation :"
   ],
   "id": "95db739687b59c13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def coefficient_determination(x: Matrix, y: Matrix, theta: Matrix) -> float:\n",
    "    n: int = y.shape()[0]\n",
    "    predictions: Matrix = model(x, theta)\n",
    "    means: Matrix = Matrix([[y.mean()] for _ in range(n)])\n",
    "    return 1 - ((y - predictions).square().sum() / (y - means).square().sum())"
   ],
   "id": "4268c83e44adaa56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
